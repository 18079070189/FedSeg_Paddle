os.getcwd():  /home/mjx/MIAO_code_noshare_g_ditill/bisenetv2_fedavg_miao

Experimental details:
    Dataset                 : camvid
    Dataset root_dir        : ../camvid_erase_11C1
    USE_ERASE_DATA          : True
    Number of classes       : 11
    Split data (train data) : train
    Model                   : bisenetv2
    resume from Checkpoint  : 
    Optimizer               : sgd
    Scheduler               : step
    Learning rate           : 0.05
    Momentum                : 0.99
    weight decay            : 0.0005
    Global Rounds           : 800

    Federated parameters:
    Non-IID
    Number of global users  : 22
    Fraction num of users   : 5
    Local Epochs            : 2
    Local Batch size        : 8

    Logging parameters:
    save_frequency          : 20
    local_test_frequency    : 9999
    global_test_frequency   : 20
    USE_WANDB               : False

device: cuda
['bicyclist', 'building', 'car', 'column_pole', 'fence', 'pedestrian', 'road', 'sidewalk', 'sing_symbol', 'sky', 'tree']
[0, 48, 90, 132, 174, 216, 258, 300, 342, 384, 426]
['bicyclist', 'building', 'car', 'column_pole', 'fence', 'pedestrian', 'road', 'sidewalk', 'sing_symbol', 'sky', 'tree']
[0, 48, 90, 132, 174, 216, 258, 300, 342, 384, 426]
find 468 examples
['all']
[0]
['all']
[0]
find 233 examples

Getting non-iid user indices for cityscapes: 
city_names:  ['bicyclist', 'building', 'car', 'column_pole', 'fence', 'pedestrian', 'road', 'sidewalk', 'sing_symbol', 'sky', 'tree']
num_classes:  11
bicyclist 48
building 42
car 42
column_pole 42
fence 42
pedestrian 42
road 42
sidewalk 42
sing_symbol 42
sky 42
tree 42
city_lens:  [48, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42]
num_users_per_city: 22 / 11 = 2
Time consumed to get non-iid user indices: 0.00s

exp_name :fed_20230606_202802_train_bisenetv2_c11_e800_frac[5]_iid[False]_E[2]_B[8]_lr[0.05]_users[22]_opti[sgd]_sche[step]

Training global model on 5 of 22 users locally for 800 epochs


| Global Training Round : 0 |
local update

User idx : 7
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 6.615866
Loss_CE:6.615866

User idx : 9
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 8.409440
Loss_CE:8.409440

User idx : 12
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 6.153440
Loss_CE:6.153440

User idx : 20
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 16.286600
Loss_CE:16.286600

User idx : 2
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 10.002512
Loss_CE:10.002512

| Global Training Round 0 Summary |
Local Train One global epoch loss_avg: 11.551349

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 1 |
local update

User idx : 2
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 21 images	Loss: 10.035164
Loss_CE:7.122714 | loss_contrast:0.596914 loss_pseudo: 2.315536

User idx : 10
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 21 images	Loss: 5.432988
Loss_CE:1.098584 | loss_contrast:0.660098 loss_pseudo: 3.674306

User idx : 15
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 21 images	Loss: 9.844500
Loss_CE:4.303793 | loss_contrast:2.158253 loss_pseudo: 3.382453

User idx : 1
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 0, batch_idx: 2, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 2, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 24 images	Loss: 5.650562
Loss_CE:1.872895 | loss_contrast:0.246677 loss_pseudo: 3.530990

User idx : 17
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 21 images	Loss: 8.141129
Loss_CE:3.250604 | loss_contrast:2.051064 loss_pseudo: 2.839461

| Global Training Round 1 Summary |
Local Train One global epoch loss_avg: 9.247534

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 2 |
local update

User idx : 20
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 21 images	Loss: 11.055696
Loss_CE:5.085956 | loss_contrast:0.297464 loss_pseudo: 5.672276

User idx : 11
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 21 images	Loss: 8.273760
Loss_CE:2.069443 | loss_contrast:1.950868 loss_pseudo: 4.253449

User idx : 21
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 21 images	Loss: 9.494705
Loss_CE:4.192810 | loss_contrast:0.393333 loss_pseudo: 4.908563

User idx : 18
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 21 images	Loss: 11.365230
Loss_CE:2.520483 | loss_contrast:0.476826 loss_pseudo: 8.367921

User idx : 15
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 21 images	Loss: 12.578485
Loss_CE:6.900706 | loss_contrast:1.467356 loss_pseudo: 4.210424

| Global Training Round 2 Summary |
Local Train One global epoch loss_avg: 12.214470

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 3 |
local update

User idx : 9
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 21 images	Loss: 10.409710
Loss_CE:3.209009 | loss_contrast:3.460115 loss_pseudo: 3.740586

User idx : 5
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 21 images	Loss: 11.267415
Loss_CE:4.118187 | loss_contrast:2.671367 loss_pseudo: 4.477860

User idx : 17
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 21 images	Loss: 8.841672
Loss_CE:1.861212 | loss_contrast:3.203362 loss_pseudo: 3.777098

User idx : 21
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 21 images	Loss: 10.063207
Loss_CE:5.146412 | loss_contrast:0.821584 loss_pseudo: 4.095211

User idx : 4
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 21 images	Loss: 12.502977
Loss_CE:5.646517 | loss_contrast:2.449230 loss_pseudo: 4.407230

| Global Training Round 3 Summary |
Local Train One global epoch loss_avg: 11.831630

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 4 |
local update

User idx : 14
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 21 images	Loss: 9.439283
Loss_CE:3.067199 | loss_contrast:2.914789 loss_pseudo: 3.457295

User idx : 3
Extracting prototypes...
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 21 images	Loss: 9.989367
Loss_CE:5.150160 | loss_contrast:1.344417 loss_pseudo: 3.494789

User idx : 16
