os.getcwd():  /home/mjx/MIAO_code_noshare_g_ditill/bisenetv2_fedavg_miao

Experimental details:
    Dataset                 : camvid
    Dataset root_dir        : ../camvid_erase_11C1
    USE_ERASE_DATA          : True
    Number of classes       : 11
    Split data (train data) : train
    Model                   : bisenetv2
    resume from Checkpoint  : 
    Optimizer               : sgd
    Scheduler               : step
    Learning rate           : 0.05
    Momentum                : 0.99
    weight decay            : 0.0005
    Global Rounds           : 800

    Federated parameters:
    Non-IID
    Number of global users  : 22
    Fraction num of users   : 5
    Local Epochs            : 2
    Local Batch size        : 8

    Logging parameters:
    save_frequency          : 20
    local_test_frequency    : 9999
    global_test_frequency   : 20
    USE_WANDB               : False

device: cuda
['bicyclist', 'building', 'car', 'column_pole', 'fence', 'pedestrian', 'road', 'sidewalk', 'sing_symbol', 'sky', 'tree']
[0, 48, 90, 132, 174, 216, 258, 300, 342, 384, 426]
['bicyclist', 'building', 'car', 'column_pole', 'fence', 'pedestrian', 'road', 'sidewalk', 'sing_symbol', 'sky', 'tree']
[0, 48, 90, 132, 174, 216, 258, 300, 342, 384, 426]
find 468 examples
['all']
[0]
['all']
[0]
find 233 examples

Getting non-iid user indices for cityscapes: 
city_names:  ['bicyclist', 'building', 'car', 'column_pole', 'fence', 'pedestrian', 'road', 'sidewalk', 'sing_symbol', 'sky', 'tree']
num_classes:  11
bicyclist 48
building 42
car 42
column_pole 42
fence 42
pedestrian 42
road 42
sidewalk 42
sing_symbol 42
sky 42
tree 42
city_lens:  [48, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42]
num_users_per_city: 22 / 11 = 2
Time consumed to get non-iid user indices: 0.00s

exp_name :fed_20230606_202720_train_bisenetv2_c11_e800_frac[5]_iid[False]_E[2]_B[8]_lr[0.05]_users[22]_opti[sgd]_sche[step]

Training global model on 5 of 22 users locally for 800 epochs


| Global Training Round : 0 |
local update

User idx : 3
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 7.466451
Loss_CE:7.466451

User idx : 11
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 3.187267
Loss_CE:3.187267

User idx : 9
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 7.230123
Loss_CE:7.230123

User idx : 13
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 7.807109
Loss_CE:7.807109

User idx : 21
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 21 images	Loss: 11.578169
Loss_CE:11.578169

| Global Training Round 0 Summary |
Local Train One global epoch loss_avg: 9.692400

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 1 |
local update

User idx : 16
Extracting prototypes...
tensor([ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,
         35,  36,  37,  38,  39,  40,  41,  64,  66,  67,  68,  69,  70,  71,
         73,  74,  76,  77,  78,  79,  80,  81,  82,  83, 106, 107, 108, 109,
        110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 126, 127,
        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
        142, 143, 144, 145, 146, 149, 151, 191, 193, 194, 195, 196, 202, 203,
        206, 207, 209], device='cuda:0')
tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,
         1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,
         2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,
         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,
         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,
         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,
         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,
         6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,
         7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,
         8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,
         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10,
        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10])
