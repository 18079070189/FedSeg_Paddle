os.getcwd():  /root/paddlejob/workspace/env_run/bisenetv2_fedavg_miao

Experimental details:
    Dataset                 : cityscapes
    Dataset root_dir        : ../data/cityscapes_split_erase19
    USE_ERASE_DATA          : True
    Number of classes       : 19
    Split data (train data) : train
    Model                   : bisenetv2
    resume from Checkpoint  : 
    Optimizer               : sgd
    Scheduler               : step
    Learning rate           : 0.05
    Momentum                : 0.99
    weight decay            : 0.0005
    Global Rounds           : 1500

    Federated parameters:
    Non-IID
    Number of global users  : 152
    Fraction num of users   : 5
    Local Epochs            : 2
    Local Batch size        : 8

    Logging parameters:
    save_frequency          : 20
    local_test_frequency    : 9999
    global_test_frequency   : 20
    USE_WANDB               : False

device: cuda
find 2975 examples
find 500 examples

Getting non-iid user indices for cityscapes: 
city_names:  ['bicycle', 'building', 'bus', 'car', 'fence', 'motorcycle', 'person', 'pole', 'rider', 'road', 'sidewalk', 'sky', 'terrain', 'traffic_light', 'traffic_sign', 'train', 'truck', 'vegetation', 'wall']
num_classes:  19
bicycle 156
building 156
bus 156
car 181
fence 156
motorcycle 156
person 156
pole 156
rider 156
road 156
sidewalk 156
sky 156
terrain 156
traffic_light 156
traffic_sign 156
train 142
truck 156
vegetation 156
wall 156
city_lens:  [156, 156, 156, 181, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 142, 156, 156, 156]
num_users_per_city: 152 / 19 = 8
Time consumed to get non-iid user indices: 0.01s

exp_name :fed_20220817_220140_train_bisenetv2_c19_e1500_frac[5]_iid[False]_E[2]_B[8]_lr[0.05]_users[152]_opti[sgd]_sche[step]

Training global model on 5 of 152 users locally for 1500 epochs


| Global Training Round : 0 |
Extracting prototypes finished
local update

User idx : 4
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 3.994444
Loss_CE:3.994444 | loss_contrast:0.000000

User idx : 46
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 6.722480
Loss_CE:6.722480 | loss_contrast:0.000000

User idx : 57
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 9.569063
Loss_CE:9.569063 | loss_contrast:0.000000

User idx : 10
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 7.513150
Loss_CE:7.513150 | loss_contrast:0.000000

User idx : 105
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 2.788264
Loss_CE:2.788264 | loss_contrast:0.000000

| Global Training Round 0 Summary |
Local Train One global epoch loss_avg: 6.780704

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 1 |
Extracting prototypes finished
local update

User idx : 136
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 6.444493
Loss_CE:6.444493 | loss_contrast:0.000000

User idx : 108
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 0.401941
Loss_CE:0.401941 | loss_contrast:0.000000

User idx : 33
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 3.562996
Loss_CE:3.562996 | loss_contrast:0.000000

User idx : 37
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 3.686392
Loss_CE:3.686392 | loss_contrast:0.000000

User idx : 135
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 23 images	Loss: 4.157123
Loss_CE:4.157123 | loss_contrast:0.000000

| Global Training Round 1 Summary |
Local Train One global epoch loss_avg: 3.948971

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 2 |
Extracting prototypes...

User idx : 50

User idx : 43

User idx : 15

User idx : 18

User idx : 66
Extracting prototypes finished
local update

User idx : 50
tensor(1.5736, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(1.5690, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(1.5739, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(1.5757, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 3.765621
Loss_CE:3.608049 | loss_contrast:1.575727

User idx : 43
tensor(1.5450, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(1.5661, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(1.5844, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(1.5645, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 1.197698
Loss_CE:1.041247 | loss_contrast:1.564506

User idx : 15
tensor(1.5988, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(1.5793, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(1.5736, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(1.5465, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 23 images	Loss: 7.497028
Loss_CE:7.342376 | loss_contrast:1.546522

User idx : 18
tensor(1.5909, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(1.5956, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(1.5901, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(1.5934, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 4.727606
Loss_CE:4.568264 | loss_contrast:1.593424

User idx : 66
tensor(1.5618, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(1.5791, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(1.5600, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(1.5801, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 1.207665
Loss_CE:1.049660 | loss_contrast:1.580057

| Global Training Round 2 Summary |
Local Train One global epoch loss_avg: 3.562588

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 3 |
Extracting prototypes...

User idx : 45

User idx : 66

User idx : 38

User idx : 13

User idx : 126
Extracting prototypes finished
local update

User idx : 45
tensor(16.6021, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: nan
Loss_CE:nan | loss_contrast:nan

User idx : 66
tensor(14.6115, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(6.9536, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(1.6074, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(1.6089, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 0.632693
Loss_CE:0.471807 | loss_contrast:1.608864

User idx : 38
tensor(14.2204, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: nan
Loss_CE:nan | loss_contrast:nan

User idx : 13
tensor(9.7089, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: nan
Loss_CE:nan | loss_contrast:nan

User idx : 126
tensor(12.1369, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
**********
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 17 images	Loss: nan
Loss_CE:nan | loss_contrast:nan

| Global Training Round 3 Summary |
Local Train One global epoch loss_avg: nan

Weight averaging
using weighted_average_weights
