os.getcwd():  /root/paddlejob/workspace/env_run/bisenetv2_fedavg_miao

Experimental details:
    Dataset                 : cityscapes
    Dataset root_dir        : ../data/cityscapes_split_erase19
    USE_ERASE_DATA          : True
    Number of classes       : 19
    Split data (train data) : train
    Model                   : bisenetv2
    resume from Checkpoint  : 
    Optimizer               : sgd
    Scheduler               : step
    Learning rate           : 0.05
    Momentum                : 0.99
    weight decay            : 0.0005
    Global Rounds           : 1500

    Federated parameters:
    Non-IID
    Number of global users  : 152
    Fraction num of users   : 5
    Local Epochs            : 2
    Local Batch size        : 8

    Logging parameters:
    save_frequency          : 20
    local_test_frequency    : 9999
    global_test_frequency   : 20
    USE_WANDB               : False

device: cuda
find 2975 examples
find 500 examples

Getting non-iid user indices for cityscapes: 
city_names:  ['bicycle', 'building', 'bus', 'car', 'fence', 'motorcycle', 'person', 'pole', 'rider', 'road', 'sidewalk', 'sky', 'terrain', 'traffic_light', 'traffic_sign', 'train', 'truck', 'vegetation', 'wall']
num_classes:  19
bicycle 156
building 156
bus 156
car 181
fence 156
motorcycle 156
person 156
pole 156
rider 156
road 156
sidewalk 156
sky 156
terrain 156
traffic_light 156
traffic_sign 156
train 142
truck 156
vegetation 156
wall 156
city_lens:  [156, 156, 156, 181, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 142, 156, 156, 156]
num_users_per_city: 152 / 19 = 8
Time consumed to get non-iid user indices: 0.01s

exp_name :fed_20220907_195314_train_bisenetv2_c19_e1500_frac[5]_iid[False]_E[2]_B[8]_lr[0.05]_users[152]_opti[sgd]_sche[step]

Training global model on 5 of 152 users locally for 1500 epochs


| Global Training Round : 0 |
Extracting prototypes finished
local update

User idx : 41
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 6.495566
Loss_CE:6.495566

User idx : 100
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 13.209937
Loss_CE:13.209937

User idx : 4
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 2.719316
Loss_CE:2.719316

User idx : 139
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 8.856205
Loss_CE:8.856205

User idx : 131
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 6.086776
Loss_CE:6.086776

| Global Training Round 0 Summary |
Local Train One global epoch loss_avg: 8.525735

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 1 |
Extracting prototypes...

User idx : 148

User idx : 96

User idx : 76

User idx : 131

User idx : 72
Extracting prototypes finished
local update

User idx : 148
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 10.682263
Loss_CE:3.572869 | loss_contrast:2.973209 loss_pseudo: 4.136186

User idx : 96
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 9.006767
Loss_CE:2.397646 | loss_contrast:1.921506 loss_pseudo: 4.687616

User idx : 76
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 12.672026
Loss_CE:6.014366 | loss_contrast:1.733235 loss_pseudo: 4.924425

User idx : 131
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 8.201815
Loss_CE:1.764659 | loss_contrast:2.332591 loss_pseudo: 4.104563

User idx : 72
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 13.665788
Loss_CE:6.861412 | loss_contrast:2.279570 loss_pseudo: 4.524806

| Global Training Round 1 Summary |
Local Train One global epoch loss_avg: 13.470504

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 2 |
Extracting prototypes...

User idx : 12

User idx : 130

User idx : 132

User idx : 14

User idx : 140
Extracting prototypes finished
local update

User idx : 12
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 14.526464
Loss_CE:7.306534 | loss_contrast:3.147161 loss_pseudo: 4.072769

User idx : 130
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 8.823280
Loss_CE:2.442593 | loss_contrast:2.865258 loss_pseudo: 3.515430

User idx : 132
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 8.724397
Loss_CE:2.768002 | loss_contrast:2.630449 loss_pseudo: 3.325946

User idx : 14
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 19.701071
Loss_CE:13.017590 | loss_contrast:3.097671 loss_pseudo: 3.585810

User idx : 140
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 11.139502
Loss_CE:3.613465 | loss_contrast:2.407081 loss_pseudo: 5.118955

| Global Training Round 2 Summary |
Local Train One global epoch loss_avg: 13.977979

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 3 |
Extracting prototypes...

User idx : 93

User idx : 110

User idx : 130

User idx : 61

User idx : 6
Extracting prototypes finished
local update

User idx : 93
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 7.951413
Loss_CE:2.174945 | loss_contrast:2.355321 loss_pseudo: 3.421147

User idx : 110
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 7.350897
Loss_CE:0.405459 | loss_contrast:3.874142 loss_pseudo: 3.071296

User idx : 130
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 7.423882
Loss_CE:1.871742 | loss_contrast:2.377490 loss_pseudo: 3.174651

User idx : 61
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 7.611955
Loss_CE:0.846956 | loss_contrast:3.536944 loss_pseudo: 3.228054

User idx : 6
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 7.748370
Loss_CE:1.202124 | loss_contrast:3.074126 loss_pseudo: 3.472120

| Global Training Round 3 Summary |
Local Train One global epoch loss_avg: 8.671408

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 4 |
Extracting prototypes...

User idx : 108

User idx : 40

User idx : 57

User idx : 134

User idx : 86
Extracting prototypes finished
local update

User idx : 108
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 19 images	Loss: 7.607421
Loss_CE:0.200382 | loss_contrast:3.805068 loss_pseudo: 3.601970

User idx : 40
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 19 images	Loss: 7.031861
Loss_CE:0.189452 | loss_contrast:3.415124 loss_pseudo: 3.427285

User idx : 57
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 19 images	Loss: 7.844949
Loss_CE:0.849352 | loss_contrast:3.347623 loss_pseudo: 3.647974

User idx : 134
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 19 images	Loss: 8.997135
Loss_CE:1.496617 | loss_contrast:3.624132 loss_pseudo: 3.876385

User idx : 86
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 19 images	Loss: 10.306262
Loss_CE:2.906163 | loss_contrast:3.451150 loss_pseudo: 3.948948

| Global Training Round 4 Summary |
Local Train One global epoch loss_avg: 9.663050

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 5 |
Extracting prototypes...

User idx : 125

User idx : 16

User idx : 138

User idx : 93

User idx : 27
Extracting prototypes finished
local update

User idx : 125
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 17 images	Loss: 13.132653
Loss_CE:5.107102 | loss_contrast:4.283273 loss_pseudo: 3.742278

User idx : 16
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 19 images	Loss: 9.003077
Loss_CE:1.548977 | loss_contrast:3.657439 loss_pseudo: 3.796660

User idx : 138
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 19 images	Loss: 10.202269
Loss_CE:4.330917 | loss_contrast:0.144305 loss_pseudo: 5.727047

User idx : 93
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 19 images	Loss: 7.713589
Loss_CE:3.128226 | loss_contrast:0.318219 loss_pseudo: 4.267145

User idx : 27
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 22 images	Loss: 12.804250
Loss_CE:5.246806 | loss_contrast:3.510414 loss_pseudo: 4.047029

| Global Training Round 5 Summary |
Local Train One global epoch loss_avg: 11.346929

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 6 |
Extracting prototypes...

User idx : 41

User idx : 97

User idx : 53

User idx : 122

User idx : 20
Extracting prototypes finished
local update

User idx : 41
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 6 | Local Epochs : 2 | 19 images	Loss: 8.602903
Loss_CE:1.489926 | loss_contrast:3.073610 loss_pseudo: 4.039367

User idx : 97
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 6 | Local Epochs : 2 | 19 images	Loss: 7.492558
Loss_CE:1.800264 | loss_contrast:0.554846 loss_pseudo: 5.137447

User idx : 53
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 6 | Local Epochs : 2 | 19 images	Loss: 10.955964
Loss_CE:3.389476 | loss_contrast:3.223732 loss_pseudo: 4.342756

User idx : 122
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 6 | Local Epochs : 2 | 17 images	Loss: 10.538635
Loss_CE:2.013348 | loss_contrast:3.709646 loss_pseudo: 4.815641

User idx : 20
