os.getcwd():  /root/paddlejob/workspace/env_run/bisenetv2_fedavg_miao

Experimental details:
    Dataset                 : cityscapes
    Dataset root_dir        : ../data/cityscapes_split_erase19
    USE_ERASE_DATA          : True
    Number of classes       : 19
    Split data (train data) : train
    Model                   : bisenetv2
    resume from Checkpoint  : 
    Optimizer               : sgd
    Scheduler               : step
    Learning rate           : 0.05
    Momentum                : 0.99
    weight decay            : 0.0005
    Global Rounds           : 1500

    Federated parameters:
    Non-IID
    Number of global users  : 152
    Fraction num of users   : 5
    Local Epochs            : 2
    Local Batch size        : 8

    Logging parameters:
    save_frequency          : 20
    local_test_frequency    : 9999
    global_test_frequency   : 20
    USE_WANDB               : False

device: cuda
find 2975 examples
find 500 examples

Getting non-iid user indices for cityscapes: 
city_names:  ['bicycle', 'building', 'bus', 'car', 'fence', 'motorcycle', 'person', 'pole', 'rider', 'road', 'sidewalk', 'sky', 'terrain', 'traffic_light', 'traffic_sign', 'train', 'truck', 'vegetation', 'wall']
num_classes:  19
bicycle 156
building 156
bus 156
car 181
fence 156
motorcycle 156
person 156
pole 156
rider 156
road 156
sidewalk 156
sky 156
terrain 156
traffic_light 156
traffic_sign 156
train 142
truck 156
vegetation 156
wall 156
city_lens:  [156, 156, 156, 181, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 142, 156, 156, 156]
num_users_per_city: 152 / 19 = 8
Time consumed to get non-iid user indices: 0.02s

exp_name :fed_20221019_163927_train_bisenetv2_c19_e1500_frac[5]_iid[False]_E[2]_B[8]_lr[0.05]_users[152]_opti[sgd]_sche[step]

Training global model on 5 of 152 users locally for 1500 epochs


| Global Training Round : 0 |
local update

User idx : 24
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 22 images	Loss: 0.229866

User idx : 38
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 0.296210

User idx : 70
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 0.193250

User idx : 107
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 0.209430

User idx : 149
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 0 | Local Epochs : 2 | 19 images	Loss: 0.139045

| Global Training Round 0 Summary |
Local Train One global epoch loss_avg: 33.065298

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 1 |
local update

User idx : 0
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 0.320868

User idx : 137
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 0.233840

User idx : 81
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 0.503939

User idx : 99
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 1.104379

User idx : 131
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 1 | Local Epochs : 2 | 19 images	Loss: 10.749503

| Global Training Round 1 Summary |
Local Train One global epoch loss_avg: 52.392806

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 2 |
local update

User idx : 1
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 0.650470

User idx : 142
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 0.200969

User idx : 18
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 1.198405

User idx : 132
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 1.516803

User idx : 64
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 2 | Local Epochs : 2 | 19 images	Loss: 0.395494

| Global Training Round 2 Summary |
Local Train One global epoch loss_avg: 10.990807

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 3 |
local update

User idx : 1
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 0.255005

User idx : 38
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 0.786214

User idx : 116
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 0.497280

User idx : 94
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 0.223166

User idx : 64
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 3 | Local Epochs : 2 | 19 images	Loss: 1.948078

| Global Training Round 3 Summary |
Local Train One global epoch loss_avg: 12.425339

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 4 |
local update

User idx : 138
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 19 images	Loss: 1.641368

User idx : 66
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 19 images	Loss: 0.329457

User idx : 72
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 19 images	Loss: 4.728234

User idx : 95
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 23 images	Loss: 1.074182

User idx : 131
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 4 | Local Epochs : 2 | 19 images	Loss: 0.600882

| Global Training Round 4 Summary |
Local Train One global epoch loss_avg: 10.870707

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 5 |
local update

User idx : 76
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 19 images	Loss: 0.369378

User idx : 129
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 19 images	Loss: 0.349598

User idx : 126
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 17 images	Loss: 0.823042

User idx : 1
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 19 images	Loss: 6.304003

User idx : 27
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 5 | Local Epochs : 2 | 22 images	Loss: 0.816810

| Global Training Round 5 Summary |
Local Train One global epoch loss_avg: 8.024682

Weight averaging
using weighted_average_weights

wandb not init


| Global Training Round : 6 |
local update

User idx : 147
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 6 | Local Epochs : 2 | 19 images	Loss: 4.409625

User idx : 139
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 6 | Local Epochs : 2 | 19 images	Loss: 0.965738

User idx : 134
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 6 | Local Epochs : 2 | 19 images	Loss: 0.578000

User idx : 91
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
Local Epoch: 1, batch_idx: 0, lr: 5.000e-02
Local Epoch: 1, batch_idx: 1, lr: 5.000e-02
| Global Round : 6 | Local Epochs : 2 | 19 images	Loss: 0.161468

User idx : 149
Local Epoch: 0, batch_idx: 0, lr: 5.000e-02
Local Epoch: 0, batch_idx: 1, lr: 5.000e-02
